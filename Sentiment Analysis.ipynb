{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff25c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "       textID                                               text  \\\n",
      "0  cb774db0d1                I`d have responded, if I were going   \n",
      "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
      "2  088c60f138                          my boss is bullying me...   \n",
      "3  9642c003ef                     what interview! leave me alone   \n",
      "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
      "\n",
      "                         selected_text sentiment Time of Tweet Age of User  \\\n",
      "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
      "1                             Sooo SAD  negative          noon       21-30   \n",
      "2                          bullying me  negative         night       31-45   \n",
      "3                       leave me alone  negative       morning       46-60   \n",
      "4                        Sons of ****,  negative          noon       60-70   \n",
      "\n",
      "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
      "0  Afghanistan          38928346         652860.0               60  \n",
      "1      Albania           2877797          27400.0              105  \n",
      "2      Algeria          43851044        2381740.0               18  \n",
      "3      Andorra             77265            470.0              164  \n",
      "4       Angola          32866272        1246700.0               26  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   textID            27481 non-null  object \n",
      " 1   text              27480 non-null  object \n",
      " 2   selected_text     27480 non-null  object \n",
      " 3   sentiment         27481 non-null  object \n",
      " 4   Time of Tweet     27481 non-null  object \n",
      " 5   Age of User       27481 non-null  object \n",
      " 6   Country           27481 non-null  object \n",
      " 7   Population -2020  27481 non-null  int64  \n",
      " 8   Land Area (Km²)   27481 non-null  float64\n",
      " 9   Density (P/Km²)   27481 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "\n",
      "Test Data:\n",
      "       textID                                               text sentiment  \\\n",
      "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
      "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
      "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
      "3  01082688c6                                        happy bday!  positive   \n",
      "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
      "\n",
      "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
      "0       morning        0-20  Afghanistan        38928346.0         652860.0   \n",
      "1          noon       21-30      Albania         2877797.0          27400.0   \n",
      "2         night       31-45      Algeria        43851044.0        2381740.0   \n",
      "3       morning       46-60      Andorra           77265.0            470.0   \n",
      "4          noon       60-70       Angola        32866272.0        1246700.0   \n",
      "\n",
      "   Density (P/Km²)  \n",
      "0             60.0  \n",
      "1            105.0  \n",
      "2             18.0  \n",
      "3            164.0  \n",
      "4             26.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4815 entries, 0 to 4814\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   textID            3534 non-null   object \n",
      " 1   text              3534 non-null   object \n",
      " 2   sentiment         3534 non-null   object \n",
      " 3   Time of Tweet     3534 non-null   object \n",
      " 4   Age of User       3534 non-null   object \n",
      " 5   Country           3534 non-null   object \n",
      " 6   Population -2020  3534 non-null   float64\n",
      " 7   Land Area (Km²)   3534 non-null   float64\n",
      " 8   Density (P/Km²)   3534 non-null   float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 338.7+ KB\n",
      "None\n",
      "\n",
      "Manual Test Data:\n",
      "   4  3  Mon May 11 03:17:40 UTC 2009  kindle2        tpryan  \\\n",
      "0  4  4  Mon May 11 03:18:03 UTC 2009  kindle2        vcu451   \n",
      "1  4  5  Mon May 11 03:18:54 UTC 2009  kindle2        chadfu   \n",
      "2  4  6  Mon May 11 03:19:04 UTC 2009  kindle2         SIX15   \n",
      "3  4  7  Mon May 11 03:21:41 UTC 2009  kindle2      yamarama   \n",
      "4  4  8  Mon May 11 03:22:00 UTC 2009  kindle2  GeorgeVHulme   \n",
      "\n",
      "  @stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.  \n",
      "0  Reading my kindle2...  Love it... Lee childs i...                                                               \n",
      "1  Ok, first assesment of the #kindle2 ...it fuck...                                                               \n",
      "2  @kenburbary You'll love your Kindle2. I've had...                                                               \n",
      "3  @mikefish  Fair enough. But i have the Kindle2...                                                               \n",
      "4  @richardebaker no. it is too big. I'm quite ha...                                                               \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 515 entries, 0 to 514\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                                                                                           Non-Null Count  Dtype \n",
      "---  ------                                                                                                           --------------  ----- \n",
      " 0   4                                                                                                                515 non-null    int64 \n",
      " 1   3                                                                                                                515 non-null    int64 \n",
      " 2   Mon May 11 03:17:40 UTC 2009                                                                                     515 non-null    object\n",
      " 3   kindle2                                                                                                          515 non-null    object\n",
      " 4   tpryan                                                                                                           515 non-null    object\n",
      " 5   @stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.  515 non-null    object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 24.3+ KB\n",
      "None\n",
      "\n",
      "Large Train Data:\n",
      "   polarity of tweet   id of the tweet             date of the tweet  \\\n",
      "0                   0       1467810672  Mon Apr 06 22:19:49 PDT 2009   \n",
      "1                   0       1467810917  Mon Apr 06 22:19:53 PDT 2009   \n",
      "2                   0       1467811184  Mon Apr 06 22:19:57 PDT 2009   \n",
      "3                   0       1467811193  Mon Apr 06 22:19:57 PDT 2009   \n",
      "4                   0       1467811372  Mon Apr 06 22:20:00 PDT 2009   \n",
      "\n",
      "      query           user                                 text of the tweet   \n",
      "0  NO_QUERY  scotthamilton  is upset that he can't update his Facebook by ...  \n",
      "1  NO_QUERY       mattycus  @Kenichan I dived many times for the ball. Man...  \n",
      "2  NO_QUERY        ElleCTF    my whole body feels itchy and like its on fire   \n",
      "3  NO_QUERY         Karoli  @nationwideclass no, it's not behaving at all....  \n",
      "4  NO_QUERY       joy_wolf                      @Kwesidei not the whole crew   \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048572 entries, 0 to 1048571\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count    Dtype \n",
      "---  ------              --------------    ----- \n",
      " 0   polarity of tweet   1048572 non-null  int64 \n",
      " 1   id of the tweet     1048572 non-null  int64 \n",
      " 2   date of the tweet   1048572 non-null  object\n",
      " 3   query               1048572 non-null  object\n",
      " 4   user                1048572 non-null  object\n",
      " 5   text of the tweet   1048572 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 48.0+ MB\n",
      "None\n",
      "\n",
      "Train Data Sentiment Distribution:\n",
      "sentiment\n",
      "neutral     11118\n",
      "positive     8582\n",
      "negative     7781\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data Sentiment Distribution:\n",
      "sentiment\n",
      "neutral     1430\n",
      "positive    1103\n",
      "negative    1001\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify encoding\n",
    "train_df = pd.read_csv('train.csv', encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv('test.csv', encoding='ISO-8859-1')\n",
    "manual_test_df = pd.read_csv('testdata.manual.2009.06.14.csv', encoding='ISO-8859-1')\n",
    "large_train_df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Explore the datasets\n",
    "print(\"Train Data:\")\n",
    "print(train_df.head())\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_df.head())\n",
    "print(test_df.info())\n",
    "\n",
    "print(\"\\nManual Test Data:\")\n",
    "print(manual_test_df.head())\n",
    "print(manual_test_df.info())\n",
    "\n",
    "print(\"\\nLarge Train Data:\")\n",
    "print(large_train_df.head())\n",
    "print(large_train_df.info())\n",
    "\n",
    "# Check sentiment distribution in train and test datasets\n",
    "print(\"\\nTrain Data Sentiment Distribution:\")\n",
    "print(train_df['sentiment'].value_counts())\n",
    "\n",
    "print(\"\\nTest Data Sentiment Distribution:\")\n",
    "print(test_df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2069efa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Train Data:\n",
      "                                                text  \\\n",
      "0                I`d have responded, if I were going   \n",
      "1      Sooo SAD I will miss you here in San Diego!!!   \n",
      "2                          my boss is bullying me...   \n",
      "3                     what interview! leave me alone   \n",
      "4   Sons of ****, why couldn`t they put them on t...   \n",
      "\n",
      "                             cleaned_text  \n",
      "0                      id responded going  \n",
      "1                 sooo sad miss san diego  \n",
      "2                            bos bullying  \n",
      "3                   interview leave alone  \n",
      "4  son couldnt put release already bought  \n",
      "\n",
      "Preprocessed Test Data:\n",
      "                                                text  \\\n",
      "0  Last session of the day  http://twitpic.com/67ezh   \n",
      "1   Shanghai is also really exciting (precisely -...   \n",
      "2  Recession hit Veronique Branquinho, she has to...   \n",
      "3                                        happy bday!   \n",
      "4             http://twitpic.com/4w75p - I like it!!   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0                                   last session day  \n",
      "1  shanghai also really exciting precisely skyscr...  \n",
      "2  recession hit veronique branquinho quit compan...  \n",
      "3                                         happy bday  \n",
      "4                                               like  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK data\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function for preprocessing text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    words = word_tokenize(text)  # Tokenization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # Lemmatization and stop word removal\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('train.csv', encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv('test.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Fill missing values in 'text' column with an empty string\n",
    "train_df['text'].fillna('', inplace=True)\n",
    "test_df['text'].fillna('', inplace=True)\n",
    "\n",
    "# Apply preprocessing to train and test data\n",
    "train_df['cleaned_text'] = train_df['text'].apply(preprocess_text)\n",
    "test_df['cleaned_text'] = test_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Check the results\n",
    "print(\"Preprocessed Train Data:\")\n",
    "print(train_df[['text', 'cleaned_text']].head())\n",
    "print(\"\\nPreprocessed Test Data:\")\n",
    "print(test_df[['text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e62497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (21984, 5000)\n",
      "Validation Data Shape: (5497, 5000)\n",
      "Test Data Shape: (4815, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['cleaned_text'])\n",
    "X_test_tfidf = tfidf.transform(test_df['cleaned_text'])\n",
    "\n",
    "# Extract labels\n",
    "y_train = train_df['sentiment']\n",
    "y_test = test_df['sentiment']\n",
    "\n",
    "# Split the train data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of the datasets\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Validation Data Shape: {X_val.shape}\")\n",
    "print(f\"Test Data Shape: {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec6eec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Validation Accuracy: 0.6359832635983264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.49      0.59      1562\n",
      "     neutral       0.56      0.76      0.65      2230\n",
      "    positive       0.72      0.60      0.66      1705\n",
      "\n",
      "    accuracy                           0.64      5497\n",
      "   macro avg       0.67      0.62      0.63      5497\n",
      "weighted avg       0.66      0.64      0.63      5497\n",
      "\n",
      "Unique values in y_test: ['neutral' 'positive' 'negative' 'nan']\n",
      "Naive Bayes Test Accuracy: 0.4664589823468328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nan       0.00      0.00      0.00      1281\n",
      "    negative       0.72      0.52      0.60      1001\n",
      "     neutral       0.33      0.75      0.46      1430\n",
      "    positive       0.74      0.60      0.66      1103\n",
      "\n",
      "    accuracy                           0.47      4815\n",
      "   macro avg       0.45      0.47      0.43      4815\n",
      "weighted avg       0.42      0.47      0.41      4815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on validation data\n",
    "y_val_pred_nb = nb.predict(X_val)\n",
    "print(\"Naive Bayes Validation Accuracy:\", accuracy_score(y_val, y_val_pred_nb))\n",
    "print(classification_report(y_val, y_val_pred_nb))\n",
    "\n",
    "# Assuming `test_df` is your test DataFrame with the necessary columns\n",
    "# Define `y_test` from the `test_df` if not already done\n",
    "y_test = test_df['sentiment']\n",
    "\n",
    "# Ensure `y_test` is a pandas Series of strings (sentiment labels)\n",
    "y_test = y_test.astype(str)\n",
    "\n",
    "# Check unique values in y_test to ensure correctness\n",
    "print(\"Unique values in y_test:\", y_test.unique())\n",
    "\n",
    "# Now you can proceed with evaluating the model predictions\n",
    "y_test_pred_nb = nb.predict(X_test_tfidf)\n",
    "\n",
    "# Convert predictions to strings if necessary\n",
    "y_test_pred_nb = y_test_pred_nb.astype(str)\n",
    "\n",
    "# Evaluate the Naive Bayes model on test data\n",
    "print(\"Naive Bayes Test Accuracy:\", accuracy_score(y_test, y_test_pred_nb))\n",
    "print(classification_report(y_test, y_test_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233db1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Validation Accuracy: 0.6951064216845552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.56      0.65      1562\n",
      "     neutral       0.62      0.80      0.70      2230\n",
      "    positive       0.78      0.68      0.73      1705\n",
      "\n",
      "    accuracy                           0.70      5497\n",
      "   macro avg       0.73      0.68      0.69      5497\n",
      "weighted avg       0.71      0.70      0.69      5497\n",
      "\n",
      "SVM Test Accuracy: 0.5111111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nan       0.00      0.00      0.00      1281\n",
      "    negative       0.75      0.57      0.65      1001\n",
      "     neutral       0.36      0.79      0.50      1430\n",
      "    positive       0.81      0.69      0.74      1103\n",
      "\n",
      "    accuracy                           0.51      4815\n",
      "   macro avg       0.48      0.51      0.47      4815\n",
      "weighted avg       0.45      0.51      0.45      4815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train an SVM classifier\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on validation data\n",
    "y_val_pred_svm = svm.predict(X_val)\n",
    "print(\"SVM Validation Accuracy:\", accuracy_score(y_val, y_val_pred_svm))\n",
    "print(classification_report(y_val, y_val_pred_svm))\n",
    "\n",
    "# Predict and evaluate on test data\n",
    "y_test_pred_svm = svm.predict(X_test_tfidf)\n",
    "print(\"SVM Test Accuracy:\", accuracy_score(y_test, y_test_pred_svm))\n",
    "print(classification_report(y_test, y_test_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1927dafa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Accuracy: 0.6825541204293251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.59      0.65      1562\n",
      "     neutral       0.62      0.75      0.68      2230\n",
      "    positive       0.76      0.69      0.72      1705\n",
      "\n",
      "    accuracy                           0.68      5497\n",
      "   macro avg       0.70      0.67      0.68      5497\n",
      "weighted avg       0.69      0.68      0.68      5497\n",
      "\n",
      "Logistic Regression Test Accuracy: 0.5044652128764279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nan       0.00      0.00      0.00      1281\n",
      "    negative       0.70      0.61      0.66      1001\n",
      "     neutral       0.35      0.74      0.48      1430\n",
      "    positive       0.79      0.69      0.74      1103\n",
      "\n",
      "    accuracy                           0.50      4815\n",
      "   macro avg       0.46      0.51      0.47      4815\n",
      "weighted avg       0.43      0.50      0.45      4815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on validation data\n",
    "y_val_pred_lr = lr.predict(X_val)\n",
    "print(\"Logistic Regression Validation Accuracy:\", accuracy_score(y_val, y_val_pred_lr))\n",
    "print(classification_report(y_val, y_val_pred_lr))\n",
    "\n",
    "# Predict and evaluate on test data\n",
    "y_test_pred_lr = lr.predict(X_test_tfidf)\n",
    "print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_test_pred_lr))\n",
    "print(classification_report(y_test, y_test_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72f20ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Naive Bayes: {'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'alpha': [0.01, 0.1, 1]}\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters for Naive Bayes:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800f0d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.62701842 0.62656357 0.63133955 0.63179441 0.62875341]\n",
      "Mean CV Score: 0.6290938709762198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "nb_best_model = MultinomialNB(alpha=grid_search.best_params_['alpha'])\n",
    "scores = cross_val_score(nb_best_model, X_train, y_train, cv=5)\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Mean CV Score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a686d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4163f808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f519d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
